{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# set the random state\n",
    "np.random.seed(seed=300)\n",
    "\n",
    "# load train and test data\n",
    "train = np.loadtxt(open(os.path.join('input', 'optdigits.tra'), \"rb\"), delimiter=\",\")\n",
    "test =np.loadtxt(open(os.path.join('input', 'optdigits.tes'), \"rb\"), delimiter=\",\")\n",
    "\n",
    "# Define labels for confusion matrix figure\n",
    "tick_label = ['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "# Slicing features and labels from train and test data\n",
    "X_train = train[:,:64]\n",
    "y_train = train[:,64]\n",
    "X_test = test[:,:64]\n",
    "y_test = test[:,64]\n",
    "\n",
    "\n",
    "# spliting train set into 90% train and 10% validation set\n",
    "Xtr, Xval, ytr, yval = train_test_split(X_train, y_train, test_size=0.10)\n",
    "\n",
    "\n",
    "\n",
    "# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "# define a function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print(title)\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig(title)\n",
    "\n",
    "\n",
    "\n",
    "# compute accuracy per class\n",
    "def acc_per_class(conf_train, conf_test, flag=False):\n",
    "    if flag:\n",
    "        print('Class    train accuracy     test accuracy')\n",
    "    else:\n",
    "        print('Class    Before Removal   After Removal')\n",
    "    for i in range(10):\n",
    "        train_acc = float(conf_train[i,i])/np.sum(conf_train[i,:])\n",
    "        test_acc = float(conf_test[i,i])/np.sum(conf_test[i,:])\n",
    "        print(' {}       {:.4f}           {:.4f}'.format(i, train_acc, test_acc))      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################\n",
      "Hyper-parameters tunning for knn...\n",
      "##################################################\n",
      "Best n_neighbors: 1\n",
      "\n",
      "Validation accuracy (KNN): 0.9896\n",
      "\n",
      "Computing knn training time...\n",
      "n_neighbors: 1, training took 0.0064 seconds.\n",
      "\n",
      "Confusion Matrix of KNN (Train)\n",
      "[[376   0   0   0   0   0   0   0   0   0]\n",
      " [  0 389   0   0   0   0   0   0   0   0]\n",
      " [  0   0 380   0   0   0   0   0   0   0]\n",
      " [  0   0   0 389   0   0   0   0   0   0]\n",
      " [  0   0   0   0 387   0   0   0   0   0]\n",
      " [  0   0   0   0   0 376   0   0   0   0]\n",
      " [  0   0   0   0   0   0 377   0   0   0]\n",
      " [  0   0   0   0   0   0   0 387   0   0]\n",
      " [  0   0   0   0   0   0   0   0 380   0]\n",
      " [  0   0   0   0   0   0   0   0   0 382]]\n",
      "\n",
      "Computing knn test time...\n",
      "n_neighbors: 1 test took 0.5024 seconds.\n",
      "\n",
      "Test accuracy (KNN): 0.9800\n",
      "\n",
      "Confusion Matrix of KNN (Test)\n",
      "[[178   0   0   0   0   0   0   0   0   0]\n",
      " [  0 181   0   0   0   0   0   0   1   0]\n",
      " [  0   2 175   0   0   0   0   0   0   0]\n",
      " [  0   0   0 179   0   0   0   2   0   2]\n",
      " [  0   2   0   0 178   0   0   0   1   0]\n",
      " [  0   0   0   0   1 179   0   0   0   2]\n",
      " [  0   0   0   0   0   0 181   0   0   0]\n",
      " [  0   0   0   0   0   0   0 177   0   2]\n",
      " [  0   8   0   1   0   0   0   0 164   1]\n",
      " [  0   0   0   3   3   2   0   0   3 169]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##################################################\n",
    "#\t\t\t\t\t\t\t\t\t\t\t\t #\n",
    "# tuning the hyper-parameter k of KNN Classifier #\n",
    "#\t\t\t\t\t\t\t\t\t\t\t\t #\n",
    "##################################################\t \n",
    "\n",
    "# k values (1, 3, 5, 7, ... , 19)\n",
    "k_array = np.arange(1,20,2)\n",
    "\n",
    "# an empty list to store validation accuracies\n",
    "val_scores_knn = []\n",
    "\n",
    "# compute knn classifier accuracy for each k\n",
    "print(\"\\n\"+50*\"#\")\n",
    "print('Hyper-parameters tunning for knn...')\n",
    "print(50*\"#\")\n",
    "best_knn = None\n",
    "best_acc_knn = -1\n",
    "for k in k_array:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(Xtr, ytr)\n",
    "    val_acc_knn = knn.score(Xval, yval) # accuracy for validation set\n",
    "    val_scores_knn.append(val_acc_knn)\n",
    "    if val_acc_knn > best_acc_knn:\n",
    "    \tbest_knn = knn\n",
    "    \tbest_acc_knn = val_acc_knn\n",
    "\n",
    "# choose the optimal k\n",
    "best_k = k_array[val_scores_knn.index(max(val_scores_knn))]\n",
    "\n",
    "\n",
    "print (\"Best n_neighbors: {}\\n\".format(best_k))\n",
    "\n",
    "# Best model accuracy on validation set\n",
    "print(\"Validation accuracy (KNN): {:.4f}\".format(best_knn.score(Xval, yval)))\n",
    "\n",
    "\n",
    "\n",
    "# compute knn train time\n",
    "print('\\nComputing knn training time...')\n",
    "start = time.time()\n",
    "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn.fit(X_train, y_train)\n",
    "print(\"n_neighbors: {}, training took {:.4f} seconds.\\n\".format(best_k, time.time() - start))\n",
    "\n",
    "y_pred_train_knn = knn.predict(X_train)\n",
    "conf_knn_train = confusion_matrix(y_train, y_pred_train_knn)\n",
    "plot_confusion_matrix(conf_knn_train, classes=tick_label, title=\"Confusion Matrix of KNN (Train)\")\n",
    "\n",
    "\n",
    "\n",
    "# compute knn test time\n",
    "start = time.time()\n",
    "print('\\nComputing knn test time...')\n",
    "y_pred_test_knn = knn.predict(X_test)\n",
    "print(\"n_neighbors: {} test took {:.4f} seconds.\\n\".format(best_k, time.time() - start))\n",
    "print(\"Test accuracy (KNN): {:.4f}\\n\".format(knn.score(X_test, y_test)))\n",
    "\n",
    "# plot test set confusion matrix\n",
    "conf_knn_test = confusion_matrix(y_test, y_pred_test_knn)\n",
    "plot_confusion_matrix(conf_knn_test, classes=tick_label, title=\"Confusion Matrix of KNN (Test)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "##################################################\n",
      "Hyper-parameters tunning for Decision Tree...\n",
      "##################################################\n",
      "Best max_depth: 33\n",
      "\n",
      "Validation accuracy (Decision Tree): 0.9217\n",
      "\n",
      "\n",
      "Computing Decision Tree training time...\n",
      "max_depth: 33, training took 0.0393 seconds.\n",
      "\n",
      "Confusion Matrix of Decision Tree (Train)\n",
      "[[376   0   0   0   0   0   0   0   0   0]\n",
      " [  0 389   0   0   0   0   0   0   0   0]\n",
      " [  0   0 380   0   0   0   0   0   0   0]\n",
      " [  0   0   0 389   0   0   0   0   0   0]\n",
      " [  0   0   0   0 387   0   0   0   0   0]\n",
      " [  0   0   0   0   0 376   0   0   0   0]\n",
      " [  0   0   0   0   0   0 377   0   0   0]\n",
      " [  0   0   0   0   0   0   0 387   0   0]\n",
      " [  0   0   0   0   0   0   0   0 380   0]\n",
      " [  0   0   0   0   0   0   0   0   0 382]]\n",
      "\n",
      "Computing Decision Tree test time...\n",
      "max_depth: 33, test took 0.0007 seconds.\n",
      "\n",
      "Test accuracy (Decision Tree): 0.8559\n",
      "\n",
      "Confusion Matrix of Decision Tree (Test)\n",
      "[[173   0   1   0   2   2   0   0   0   0]\n",
      " [  0 161   0   7   1   1   2   1   2   7]\n",
      " [  1   7 142   4   2   0   2  10   7   2]\n",
      " [  0   4   6 152   0   3   0   5   6   7]\n",
      " [  7  11   0   0 141   2   5   1  12   2]\n",
      " [  1   5   5   2   1 160   6   0   0   2]\n",
      " [  0   2   2   0   2   0 172   0   3   0]\n",
      " [  2   4   9   0   9   3   0 135  12   5]\n",
      " [  1   8   2   1   2   5   0   3 146   6]\n",
      " [  0   6   1   6   4   3   0   0   4 156]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##################################################\n",
    "#\t\t\t\t\t\t\t\t\t\t\t\t #\n",
    "# \tTuning the hyper-parameter: max depth of \t #\n",
    "#\t\t\t\tDecision Tree\t\t\t\t\t #\n",
    "#\t\t\t\t\t\t\t\t\t\t\t\t #\n",
    "##################################################\t \n",
    "\n",
    "# set an aray of max depth values\n",
    "max_depth_array = np.arange(1,51)\n",
    "\n",
    "# an empty list to store validation accuracies\n",
    "val_scores_dtree = []\n",
    "\n",
    "# compute dtree classifier accuracy for each max depth\n",
    "print(\"\\n\\n\"+50*\"#\")\n",
    "print('Hyper-parameters tunning for Decision Tree...')\n",
    "print(50*\"#\")\n",
    "best_dtree = None\n",
    "best_acc_dtree = -1\n",
    "for d in max_depth_array:\n",
    "    dtree = tree.DecisionTreeClassifier(max_depth=d)\n",
    "    dtree.fit(Xtr, ytr)\n",
    "    val_acc_dtree = dtree.score(Xval, yval) # accuracy for validation set\n",
    "    val_scores_dtree.append(val_acc_dtree)\n",
    "    if val_acc_dtree > best_acc_dtree:\n",
    "    \tbest_dtree = dtree\n",
    "    \tbest_acc_dtree = val_acc_dtree\n",
    "\n",
    "# choose the best max depth\n",
    "best_depth = max_depth_array[val_scores_dtree.index(max(val_scores_dtree))]\n",
    "\n",
    "\n",
    "print (\"Best max_depth: {}\\n\".format(best_depth))\n",
    "\n",
    "\n",
    "# Classification accuracy on validation set\n",
    "print(\"Validation accuracy (Decision Tree): {:.4f}\\n\".format(best_dtree.score(Xval, yval)))\n",
    "\n",
    "\n",
    "# compute Deision tree train time\n",
    "print('\\nComputing Decision Tree training time...')\n",
    "start = time.time()\n",
    "dtree = tree.DecisionTreeClassifier(max_depth=best_depth)\n",
    "dtree.fit(X_train, y_train)\n",
    "print(\"max_depth: {}, training took {:.4f} seconds.\\n\".format(best_depth, time.time() - start))\n",
    "\n",
    "\n",
    "# train set confusion matrix\n",
    "y_pred_train_dtree = dtree.predict(X_train)\n",
    "conf_dtree_train = confusion_matrix(y_train, y_pred_train_dtree)\n",
    "plot_confusion_matrix(conf_dtree_train, classes=tick_label, title=\"Confusion Matrix of Decision Tree (Train)\")\n",
    "\n",
    "\n",
    "# compute Deision tree test time\n",
    "start = time.time()\n",
    "print('\\nComputing Decision Tree test time...')\n",
    "y_pred_test_dtree = dtree.predict(X_test)\n",
    "print(\"max_depth: {}, test took {:.4f} seconds.\\n\".format(best_depth, time.time() - start))\n",
    "print(\"Test accuracy (Decision Tree): {:.4f}\\n\".format(dtree.score(X_test, y_test)))\n",
    "\n",
    "# plot test set confusion matrix\n",
    "conf_dtree_test = confusion_matrix(y_test, y_pred_test_dtree)\n",
    "plot_confusion_matrix(conf_dtree_test, classes=tick_label, title=\"Confusion Matrix of Decision Tree (Test)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################\n",
      "Hyper-parameters tunning for linear classifier...\n",
      "##################################################\n",
      "Best alpha: 1\n",
      "\n",
      "Validation accuracy (Linear classifier): 0.9504\n",
      "\n",
      "Computing linear classifier training time...\n",
      "alpha: 1, training took 0.0263 seconds.\n",
      "\n",
      "Confusion Matrix of linear classifier (Train)\n",
      "[[374   0   0   0   1   0   1   0   0   0]\n",
      " [  0 364   5   0   0   0   2   2  12   4]\n",
      " [  0   1 369   2   0   0   1   1   5   1]\n",
      " [  0   0   3 371   0   5   0   1   3   6]\n",
      " [  1   1   0   0 369   0   3   0   5   8]\n",
      " [  0   0   3   1   0 364   0   0   0   8]\n",
      " [  1   2   0   0   1   0 373   0   0   0]\n",
      " [  0   0   1   1   2   0   0 382   1   0]\n",
      " [  1  12   3   1   5   2   4   0 351   1]\n",
      " [  1   7   0   2   7   4   0   5   5 351]]\n",
      "\n",
      "Computing linear classifier test time...\n",
      "alpha: 1, test took 0.0010 seconds.\n",
      "\n",
      "Test accuracy (linear classifier): 0.9349\n",
      "\n",
      "Confusion Matrix of linear classifier (Test)\n",
      "[[175   0   0   0   1   2   0   0   0   0]\n",
      " [  0 161   5   0   0   1   2   0   5   8]\n",
      " [  0   1 172   1   0   0   0   2   1   0]\n",
      " [  1   1   0 165   0   3   0   3   5   5]\n",
      " [  0   1   0   0 177   0   0   1   2   0]\n",
      " [  1   0   0   0   0 179   1   0   0   1]\n",
      " [  0   2   0   0   2   0 176   0   1   0]\n",
      " [  0   0   0   0   2   7   0 164   2   4]\n",
      " [  1  12   0   0   0   5   2   0 149   5]\n",
      " [  1   2   0   1   4   3   0   0   7 162]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##################################################\n",
    "#\t\t\t\t\t\t\t\t\t\t\t\t #\n",
    "# \t\t\tTuning the hyper-parameter for \t\t #\n",
    "#\t\t\t\tlinear discrimination:  \t\t #\n",
    "#\t\t\t\tregularization penalty\t\t\t #\n",
    "#\t\t\t\t\t\t\t\t\t\t\t\t #\n",
    "##################################################\t \n",
    "\n",
    "# set regularization penalty\n",
    "regs = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "# an empty list to store validation accuracies\n",
    "val_scores_sgd = []\n",
    "\n",
    "# compute linear classifier accuracy for each regularization strength\n",
    "print('\\n'+50*'#')\n",
    "print('Hyper-parameters tunning for linear classifier...')\n",
    "print(50*'#')\n",
    "best_sgd = None\n",
    "best_acc_sgd = -1\n",
    "for reg in regs:\n",
    "    sgd = linear_model.SGDClassifier(alpha=reg)\n",
    "    sgd.fit(Xtr, ytr)\n",
    "    val_acc_sgd = sgd.score(Xval, yval) # accuracy for validation set\n",
    "    val_scores_sgd.append(val_acc_sgd)\n",
    "    if val_acc_sgd > best_acc_sgd:\n",
    "    \tbest_sgd = sgd\n",
    "    \tbest_acc_sgd = val_acc_sgd\n",
    "\n",
    "# choose the best regularization penalty\n",
    "best_reg = regs[val_scores_sgd.index(max(val_scores_sgd))]\n",
    "print (\"Best alpha: {}\\n\".format(best_reg))\n",
    "\n",
    "\n",
    "# Validation accuracy\n",
    "y_pred_val_sgd = best_sgd.predict(Xval)\n",
    "print(\"Validation accuracy (Linear classifier): {:.4f}\".format(best_sgd.score(Xval, yval)))\n",
    "\n",
    "\n",
    "# compute linear classifier train time\n",
    "print('\\nComputing linear classifier training time...')\n",
    "start = time.time()\n",
    "sgd = linear_model.SGDClassifier(alpha=best_reg)\n",
    "sgd.fit(X_train, y_train)\n",
    "print(\"alpha: {}, training took {:.4f} seconds.\\n\".format(best_reg, time.time() - start))\n",
    "\n",
    "# train set confusion matrix\n",
    "y_pred_train_sgd = sgd.predict(X_train)\n",
    "conf_sgd_train = confusion_matrix(y_train, y_pred_train_sgd)\n",
    "plot_confusion_matrix(conf_sgd_train, classes=tick_label,title=\"Confusion Matrix of linear classifier (Train)\")\n",
    "\n",
    "\n",
    "# compute linear classifier test time\n",
    "start = time.time()\n",
    "print('\\nComputing linear classifier test time...')\n",
    "y_pred_test_sgd = sgd.predict(X_test)\n",
    "print(\"alpha: {}, test took {:.4f} seconds.\\n\".format(best_reg, time.time() - start))\n",
    "print(\"Test accuracy (linear classifier): {:.4f}\\n\".format(sgd.score(X_test, y_test)))\n",
    "\n",
    "# plot test set confusion matrix\n",
    "conf_sgd_test = confusion_matrix(y_test, y_pred_test_sgd)\n",
    "plot_confusion_matrix(conf_sgd_test, classes=tick_label,title=\"Confusion Matrix of linear classifier (Test)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################\n",
      "Hyper-parameters tunning for MLP...\n",
      "##################################################\n",
      "Best hidden_layer_sizes: 64, Best alpha: 0.1\n",
      "\n",
      "Validation accuracy (MLP): 0.9948\n",
      "\n",
      "Computing MLP training time...\n",
      "hidden_layer_sizes: 64, alpha: 0.1, training took 2.1639 seconds.\n",
      "\n",
      "Confusion Matrix of MLP (Train)\n",
      "[[376   0   0   0   0   0   0   0   0   0]\n",
      " [  0 389   0   0   0   0   0   0   0   0]\n",
      " [  0   0 380   0   0   0   0   0   0   0]\n",
      " [  0   0   0 389   0   0   0   0   0   0]\n",
      " [  0   0   0   0 387   0   0   0   0   0]\n",
      " [  0   0   0   0   0 376   0   0   0   0]\n",
      " [  0   0   0   0   0   0 377   0   0   0]\n",
      " [  0   0   0   0   0   0   0 387   0   0]\n",
      " [  0   0   0   0   0   0   0   0 380   0]\n",
      " [  0   0   0   0   0   0   0   0   0 382]]\n",
      "\n",
      "Computing MLP test time...\n",
      "hidden_layer_sizes: 64, alpha: 0.1, test took 0.0030 seconds.\n",
      "Test accuracy (MLP): 0.9599\n",
      "\n",
      "Confusion Matrix of MLP (Test)\n",
      "[[177   0   0   0   0   0   1   0   0   0]\n",
      " [  0 179   0   0   0   0   1   0   2   0]\n",
      " [  0   3 169   1   0   0   4   0   0   0]\n",
      " [  0   0   4 171   0   3   0   2   1   2]\n",
      " [  0   1   0   0 175   0   0   0   3   2]\n",
      " [  0   1   1   0   0 177   0   0   0   3]\n",
      " [  0   0   0   0   2   0 178   0   1   0]\n",
      " [  0   0   0   0   0   9   0 164   0   6]\n",
      " [  0   7   0   0   0   1   0   0 160   6]\n",
      " [  1   0   1   1   0   2   0   0   0 175]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##################################################\n",
    "#\t\t\t\t\t\t\t\t\t\t\t\t #\n",
    "# \t\t\tTuning the hyper-parameter:\t\t\t #\n",
    "#\t\t\t\tMultilayer perceptron\t\t\t #\n",
    "#\t\t\t\t\t\t\t\t\t\t\t\t #\n",
    "##################################################\t \n",
    "\n",
    "\n",
    "# compute mlp classifier accuracy for each set of parameters\n",
    "print('\\n'+50*'#')\n",
    "print('Hyper-parameters tunning for MLP...')\n",
    "print(50*'#')\n",
    "\n",
    "best_mlp = None\n",
    "best_acc_mlp = -1\n",
    "best_hls = []\n",
    "best_reg = []\n",
    "hls = [64, 128, 256, (64,64), (128,128), (256,256)]\n",
    "regs = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "for hl in hls:\n",
    "    for reg in regs:\n",
    "    \tmlp = MLPClassifier(solver='adam', alpha=reg, hidden_layer_sizes=hl)\n",
    "    \tmlp.fit(Xtr, ytr)\n",
    "    \tval_acc_mlp = mlp.score(Xval, yval) # accuracy for validation set\n",
    "    \tval_scores_sgd.append(val_acc_sgd)\n",
    "    \tif val_acc_mlp > best_acc_mlp:\n",
    "    \t\tbest_mlp = mlp\n",
    "    \t\tbest_acc_mlp = val_acc_mlp\n",
    "    \t\tbest_hls = hl\n",
    "    \t\tbest_reg = reg\n",
    "\n",
    "# choose the best number of components\n",
    "#best_n_components = n_components_array[val_scores_lda.index(max(val_scores_lda))]\n",
    "\n",
    "# print best hyper-parameters\n",
    "print (\"Best hidden_layer_sizes: {}, Best alpha: {}\\n\".format(best_hls, best_reg))\n",
    "\n",
    "\n",
    "# Validation accuracy\n",
    "print(\"Validation accuracy (MLP): {:.4f}\".format(best_mlp.score(Xval, yval)))\n",
    "\n",
    "\n",
    "# compute MLP train time\n",
    "print('\\nComputing MLP training time...')\n",
    "start = time.time()\n",
    "mlp = MLPClassifier(solver='adam', alpha=best_reg, hidden_layer_sizes=best_hls)\n",
    "mlp.fit(X_train, y_train)\n",
    "print(\"hidden_layer_sizes: {}, alpha: {}, training took {:.4f} seconds.\\n\".format(best_hls, best_reg,\\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t time.time() - start))\n",
    "\n",
    "\n",
    "# plot train set confusion matrix\n",
    "y_pred_train_mlp = mlp.predict(X_train)\n",
    "conf_mlp_train = confusion_matrix(y_train, y_pred_train_mlp)\n",
    "plot_confusion_matrix(conf_mlp_train, classes=tick_label,title=\"Confusion Matrix of MLP (Train)\")\n",
    "\n",
    "\n",
    "# compute MLP test time\n",
    "start = time.time()\n",
    "print('\\nComputing MLP test time...')\n",
    "y_pred_test_mlp = mlp.predict(X_test)\n",
    "print(\"hidden_layer_sizes: {}, alpha: {}, test took {:.4f} seconds.\".format(best_hls, best_reg,\\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t time.time() - start))\n",
    "# print test accuracy MLP\n",
    "print(\"Test accuracy (MLP): {:.4f}\\n\".format(mlp.score(X_test, y_test)))\n",
    "\n",
    "# plot test set confusion matrix\n",
    "conf_mlp_test = confusion_matrix(y_test, y_pred_test_mlp)\n",
    "plot_confusion_matrix(conf_mlp_test, classes=tick_label,title=\"Confusion Matrix of MLP (Test)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "########################################\n",
      "Accuracy per class (KNN)\n",
      "Class    train accuracy     test accuracy\n",
      " 0       1.0000           1.0000\n",
      " 1       1.0000           0.9945\n",
      " 2       1.0000           0.9887\n",
      " 3       1.0000           0.9781\n",
      " 4       1.0000           0.9834\n",
      " 5       1.0000           0.9835\n",
      " 6       1.0000           1.0000\n",
      " 7       1.0000           0.9888\n",
      " 8       1.0000           0.9425\n",
      " 9       1.0000           0.9389\n",
      "\n",
      "\n",
      "########################################\n",
      "Accuracy per class (Decision Tree)\n",
      "Class    train accuracy     test accuracy\n",
      " 0       1.0000           0.9719\n",
      " 1       1.0000           0.8846\n",
      " 2       1.0000           0.8023\n",
      " 3       1.0000           0.8306\n",
      " 4       1.0000           0.7790\n",
      " 5       1.0000           0.8791\n",
      " 6       1.0000           0.9503\n",
      " 7       1.0000           0.7542\n",
      " 8       1.0000           0.8391\n",
      " 9       1.0000           0.8667\n",
      "\n",
      "\n",
      "########################################\n",
      "Accuracy per class (Linear Classifier)\n",
      "Class    train accuracy     test accuracy\n",
      " 0       0.9947           0.9831\n",
      " 1       0.9357           0.8846\n",
      " 2       0.9711           0.9718\n",
      " 3       0.9537           0.9016\n",
      " 4       0.9535           0.9779\n",
      " 5       0.9681           0.9835\n",
      " 6       0.9894           0.9724\n",
      " 7       0.9871           0.9162\n",
      " 8       0.9237           0.8563\n",
      " 9       0.9188           0.9000\n",
      "\n",
      "\n",
      "########################################\n",
      "Accuracy per class (MLP)\n",
      "Class    train accuracy     test accuracy\n",
      " 0       1.0000           0.9944\n",
      " 1       1.0000           0.9835\n",
      " 2       1.0000           0.9548\n",
      " 3       1.0000           0.9344\n",
      " 4       1.0000           0.9669\n",
      " 5       1.0000           0.9725\n",
      " 6       1.0000           0.9834\n",
      " 7       1.0000           0.9162\n",
      " 8       1.0000           0.9195\n",
      " 9       1.0000           0.9722\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# compute accuracy per class KNN \n",
    "print('\\n\\n'+40*'#')\n",
    "print('Accuracy per class (KNN)')\n",
    "acc_per_class(conf_knn_train, conf_knn_test, flag=True)\n",
    "\n",
    "\n",
    "# compute accuracy per class Decision Tree\n",
    "print('\\n\\n'+40*'#')\n",
    "print('Accuracy per class (Decision Tree)')\n",
    "acc_per_class(conf_dtree_train, conf_dtree_test, flag=True)\n",
    "\n",
    "# compute accuracy per class Linear Classifier\n",
    "print('\\n\\n'+40*'#')\n",
    "print('Accuracy per class (Linear Classifier)')\n",
    "acc_per_class(conf_sgd_train, conf_sgd_test, flag=True)\n",
    "\n",
    "# compute accuracy per class MLP\n",
    "print('\\n\\n'+40*'#')\n",
    "print('Accuracy per class (MLP)')\n",
    "acc_per_class(conf_mlp_train, conf_mlp_test, flag=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "##################################################\n",
      "Number of noisy instances per model.\n",
      "knn: 0\n",
      "decision tree: 0\n",
      "linear classifier: 155\n",
      "mlp: 0\n",
      "\n",
      "Total number of missclassified instaces: 155\n",
      "4.05 percent of train data are missclasified.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##################################################\n",
    "#\t\t\t\t\t\t\t\t\t\t\t\t #\n",
    "#\t\t\t\tRemoving noisy instances \t\t #\n",
    "#\t\t\t\t\t\t\t\t\t\t\t\t #\n",
    "##################################################\n",
    "\n",
    "# Find noisy instances index per model\n",
    "idx_knn_noisy = [(y_train != y_pred_train_knn)]\n",
    "idx_dtree_noisy = [(y_train != y_pred_train_dtree)]\n",
    "idx_linear_noisy = [(y_train != y_pred_train_sgd)]\n",
    "idx_mlp_noisy = [(y_train != y_pred_train_mlp)]\n",
    "\n",
    "print('\\n\\n\\n'+50*'#')\n",
    "print('Number of noisy instances per model.')\n",
    "print('knn: {}'.format(np.sum(idx_knn_noisy)))\n",
    "print('decision tree: {}'.format(np.sum(idx_dtree_noisy)))\n",
    "print('linear classifier: {}'.format(np.sum(idx_linear_noisy)))\n",
    "print('mlp: {}'.format(np.sum(idx_mlp_noisy)))\n",
    "\n",
    "\n",
    "# Identify index of all noisy instances\n",
    "idx_noisy = [(y_train != y_pred_train_sgd) | (y_train != y_pred_train_dtree) |\\\n",
    "             (y_train != y_pred_train_knn) | (y_train != y_pred_train_mlp)]\n",
    "\n",
    "print('\\nTotal number of missclassified instaces: {}'.format(np.sum(idx_noisy)))\n",
    "\n",
    "# Find the percentage of train data that are misclassified\n",
    "noisy_percent = np.sum(idx_noisy)/float(y_train.shape[0])*100\n",
    "print('{:.2f} percent of train data are missclasified.'.format(noisy_percent))\n",
    "\n",
    "# Eliminate all noisy instances\n",
    "idx_correct = (idx_noisy[0] == False)\n",
    "X_train_new = X_train[idx_correct]\n",
    "y_train_new = y_train[idx_correct]\n",
    "\n",
    "\n",
    "# spliting new train set into 90% train and 10% validation set\n",
    "Xtr, Xval, ytr, yval = train_test_split(X_train_new, y_train_new, test_size=0.10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################\n",
      "Hyper-parameters tunning for knn after removal...\n",
      "##################################################\n",
      "Best n_neighbors after removal: 5\n",
      "\n",
      "Validation accuracy after removal (KNN): 0.9973\n",
      "\n",
      "Computing knn training time after removal ...\n",
      "n_neighbors: 5, training took 0.0062 seconds.\n",
      "\n",
      "Confusion Matrix of KNN after removal (Train)\n",
      "[[374   0   0   0   0   0   0   0   0   0]\n",
      " [  0 364   0   0   0   0   0   0   0   0]\n",
      " [  0   0 369   0   0   0   0   0   0   0]\n",
      " [  0   0   0 370   0   0   0   0   0   1]\n",
      " [  0   0   0   0 368   0   0   1   0   0]\n",
      " [  0   0   0   1   0 363   0   0   0   0]\n",
      " [  0   0   0   0   0   0 373   0   0   0]\n",
      " [  0   2   0   0   0   0   0 380   0   0]\n",
      " [  0   5   0   0   0   0   0   0 346   0]\n",
      " [  0   0   0   1   0   0   0   0   0 350]]\n",
      "\n",
      "Computing knn test time after removal ...\n",
      "n_neighbors: 5 test took 0.5295 seconds.\n",
      "\n",
      "Test accuracy after removal (KNN): 0.9750\n",
      "\n",
      "Confusion Matrix of KNN after removal (Test)\n",
      "[[178   0   0   0   0   0   0   0   0   0]\n",
      " [  0 179   1   0   0   0   1   0   1   0]\n",
      " [  0   3 174   0   0   0   0   0   0   0]\n",
      " [  0   1   0 178   0   1   0   1   2   0]\n",
      " [  0   1   0   0 177   0   0   0   3   0]\n",
      " [  0   0   0   0   1 180   0   0   0   1]\n",
      " [  0   0   0   0   0   1 180   0   0   0]\n",
      " [  0   0   0   0   0   0   0 173   1   5]\n",
      " [  0  10   0   1   0   0   0   0 161   2]\n",
      " [  0   1   0   2   1   1   0   0   3 172]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##################################################\n",
    "#\t\t\t\t\t\t\t\t\t\t\t\t #\n",
    "# tuning the hyper-parameter k of KNN Classifier #\n",
    "#                After Removal                   # \n",
    "#\t\t\t\t\t\t\t\t\t\t\t\t #\n",
    "##################################################\t \n",
    "\n",
    "# k values (1, 3, 5, 7, ... , 19)\n",
    "k_array = np.arange(1,20,2)\n",
    "\n",
    "# an empty list to store validation accuracies\n",
    "val_scores_knn = []\n",
    "\n",
    "# compute knn classifier accuracy for each k\n",
    "print(\"\\n\"+50*\"#\")\n",
    "print('Hyper-parameters tunning for knn after removal...')\n",
    "print(50*\"#\")\n",
    "best_knn = None\n",
    "best_acc_knn = -1\n",
    "for k in k_array:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(Xtr, ytr)\n",
    "    val_acc_knn = knn.score(Xval, yval) # accuracy for validation set\n",
    "    val_scores_knn.append(val_acc_knn)\n",
    "    if val_acc_knn > best_acc_knn:\n",
    "    \tbest_knn = knn\n",
    "    \tbest_acc_knn = val_acc_knn\n",
    "\n",
    "# choose the optimal k\n",
    "best_k = k_array[val_scores_knn.index(max(val_scores_knn))]\n",
    "\n",
    "\n",
    "print (\"Best n_neighbors after removal: {}\\n\".format(best_k))\n",
    "\n",
    "# Best model accuracy on validation set\n",
    "print(\"Validation accuracy after removal (KNN): {:.4f}\".format(best_knn.score(Xval, yval)))\n",
    "\n",
    "\n",
    "\n",
    "# compute knn train time\n",
    "print('\\nComputing knn training time after removal ...')\n",
    "start = time.time()\n",
    "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn.fit(X_train_new, y_train_new)\n",
    "print(\"n_neighbors: {}, training took {:.4f} seconds.\\n\".format(best_k, time.time() - start))\n",
    "\n",
    "y_pred_train_knn = knn.predict(X_train_new)\n",
    "conf_knn_train_re = confusion_matrix(y_train_new, y_pred_train_knn)\n",
    "plot_confusion_matrix(conf_knn_train_re, classes=tick_label, title=\"Confusion Matrix of KNN after removal (Train)\")\n",
    "\n",
    "\n",
    "\n",
    "# compute knn test time\n",
    "start = time.time()\n",
    "print('\\nComputing knn test time after removal ...')\n",
    "y_pred_test_knn = knn.predict(X_test)\n",
    "print(\"n_neighbors: {} test took {:.4f} seconds.\\n\".format(best_k, time.time() - start))\n",
    "print(\"Test accuracy after removal (KNN): {:.4f}\\n\".format(knn.score(X_test, y_test)))\n",
    "\n",
    "# plot test set confusion matrix\n",
    "conf_knn_test_re = confusion_matrix(y_test, y_pred_test_knn)\n",
    "plot_confusion_matrix(conf_knn_test_re, classes=tick_label, title=\"Confusion Matrix of KNN after removal (Test)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "##################################################\n",
      "Hyper-parameters tunning for Decision Tree after removal...\n",
      "##################################################\n",
      "Best max_depth after removal: 25\n",
      "\n",
      "Validation accuracy (Decision Tree) after removal: 0.9428\n",
      "\n",
      "\n",
      "Computing Decision Tree training time after removal ...\n",
      "max_depth: 25, training took 0.0363 seconds.\n",
      "\n",
      "Confusion Matrix of Decision Tree after removal (Train)\n",
      "[[374   0   0   0   0   0   0   0   0   0]\n",
      " [  0 364   0   0   0   0   0   0   0   0]\n",
      " [  0   0 369   0   0   0   0   0   0   0]\n",
      " [  0   0   0 371   0   0   0   0   0   0]\n",
      " [  0   0   0   0 369   0   0   0   0   0]\n",
      " [  0   0   0   0   0 364   0   0   0   0]\n",
      " [  0   0   0   0   0   0 373   0   0   0]\n",
      " [  0   0   0   0   0   0   0 382   0   0]\n",
      " [  0   0   0   0   0   0   0   0 351   0]\n",
      " [  0   0   0   0   0   0   0   0   0 351]]\n",
      "\n",
      "Computing Decision Tree test time after removal ...\n",
      "max_depth: 25, test took 0.0008 seconds.\n",
      "\n",
      "Test accuracy (Decision Tree) after removal: 0.8637\n",
      "\n",
      "Confusion Matrix of Decision Tree after removal (Test)\n",
      "[[170   0   0   0   2   3   1   0   2   0]\n",
      " [  0 169   3   0   2   0   0   0   1   7]\n",
      " [  1   9 137   3   0   2   1   5  16   3]\n",
      " [  1   3   6 147   2   5   0   4   6   9]\n",
      " [  0  12   0   0 154   5   3   2   4   1]\n",
      " [  0   3   0   0   2 166   3   0   3   5]\n",
      " [  0   1   1   0   2   1 173   0   3   0]\n",
      " [  0   0   0   0   4   7   0 144  16   8]\n",
      " [  0   4   9   2   3   5   0   1 146   4]\n",
      " [  1   8   3   6   5   7   0   0   4 146]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##################################################\n",
    "#\t\t\t\t\t\t\t\t\t\t\t\t #\n",
    "# \tTuning the hyper-parameter: max depth of \t #\n",
    "#\t\t\t\tDecision Tree After removal\t\t #\n",
    "#\t\t\t\t\t\t\t\t\t\t\t\t #\n",
    "##################################################\t \n",
    "\n",
    "# set an aray of max depth values\n",
    "max_depth_array = np.arange(1,51)\n",
    "\n",
    "# an empty list to store validation accuracies\n",
    "val_scores_dtree = []\n",
    "\n",
    "# compute dtree classifier accuracy for each max depth\n",
    "print(\"\\n\\n\"+50*\"#\")\n",
    "print('Hyper-parameters tunning for Decision Tree after removal...')\n",
    "print(50*\"#\")\n",
    "best_dtree = None\n",
    "best_acc_dtree = -1\n",
    "for d in max_depth_array:\n",
    "    dtree = tree.DecisionTreeClassifier(max_depth=d)\n",
    "    dtree.fit(Xtr, ytr)\n",
    "    val_acc_dtree = dtree.score(Xval, yval) # accuracy for validation set\n",
    "    val_scores_dtree.append(val_acc_dtree)\n",
    "    if val_acc_dtree > best_acc_dtree:\n",
    "    \tbest_dtree = dtree\n",
    "    \tbest_acc_dtree = val_acc_dtree\n",
    "\n",
    "# choose the best max depth\n",
    "best_depth = max_depth_array[val_scores_dtree.index(max(val_scores_dtree))]\n",
    "\n",
    "\n",
    "print (\"Best max_depth after removal: {}\\n\".format(best_depth))\n",
    "\n",
    "\n",
    "# Classification accuracy on validation set\n",
    "print(\"Validation accuracy (Decision Tree) after removal: {:.4f}\\n\".format(best_dtree.score(Xval, yval)))\n",
    "\n",
    "\n",
    "# compute Deision tree train time\n",
    "print('\\nComputing Decision Tree training time after removal ...')\n",
    "start = time.time()\n",
    "dtree = tree.DecisionTreeClassifier(max_depth=best_depth)\n",
    "dtree.fit(X_train_new, y_train_new)\n",
    "print(\"max_depth: {}, training took {:.4f} seconds.\\n\".format(best_depth, time.time() - start))\n",
    "\n",
    "\n",
    "# train set confusion matrix\n",
    "y_pred_train_dtree = dtree.predict(X_train_new)\n",
    "conf_dtree_train_re = confusion_matrix(y_train_new, y_pred_train_dtree)\n",
    "plot_confusion_matrix(conf_dtree_train_re, classes=tick_label, title=\"Confusion Matrix of Decision Tree after removal (Train)\")\n",
    "\n",
    "\n",
    "# compute Deision tree test time\n",
    "start = time.time()\n",
    "print('\\nComputing Decision Tree test time after removal ...')\n",
    "y_pred_test_dtree = dtree.predict(X_test)\n",
    "print(\"max_depth: {}, test took {:.4f} seconds.\\n\".format(best_depth, time.time() - start))\n",
    "print(\"Test accuracy (Decision Tree) after removal: {:.4f}\\n\".format(dtree.score(X_test, y_test)))\n",
    "\n",
    "# plot test set confusion matrix\n",
    "conf_dtree_test_re = confusion_matrix(y_test, y_pred_test_dtree)\n",
    "plot_confusion_matrix(conf_dtree_test_re, classes=tick_label, title=\"Confusion Matrix of Decision Tree after removal (Test)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################\n",
      "Hyper-parameters tunning for linear classifier after removal...\n",
      "##################################################\n",
      "Best alpha: 0.0001\n",
      "\n",
      "Validation accuracy (Linear classifier) after removal: 0.9837\n",
      "\n",
      "Computing linear classifier training time after removal...\n",
      "alpha: 0.0001, training took 0.0246 seconds.\n",
      "\n",
      "Confusion Matrix of linear classifier after removal (Train)\n",
      "[[370   0   1   0   1   0   0   0   0   2]\n",
      " [  0 364   0   0   0   0   0   0   0   0]\n",
      " [  0   1 363   0   0   0   0   0   1   4]\n",
      " [  0   5   0 355   0   0   0   0   0  11]\n",
      " [  0   4   0   0 357   0   0   0   0   8]\n",
      " [  0   3   1   0   0 339   6   0   0  15]\n",
      " [  0   0   0   0   0   0 373   0   0   0]\n",
      " [  0   1   0   0   0   0   0 376   0   5]\n",
      " [  0  17   0   0   0   0   5   0 327   2]\n",
      " [  0   0   0   0   0   0   0   0   0 351]]\n",
      "\n",
      "Computing linear classifier test time after removal...\n",
      "alpha: 0.0001, test took 0.0010 seconds.\n",
      "\n",
      "Test accuracy after removal (linear classifier): 0.9215\n",
      "\n",
      "Confusion Matrix of linear classifier after removal (Test)\n",
      "[[177   0   0   0   1   0   0   0   0   0]\n",
      " [  0 167   2   0   0   0   5   0   1   7]\n",
      " [  0   6 166   1   0   0   0   2   1   1]\n",
      " [  0   4   0 159   0   2   1   4   2  11]\n",
      " [  0   7   0   0 171   0   0   1   1   1]\n",
      " [  0   2   1   0   0 170   4   0   0   5]\n",
      " [  0   2   0   0   1   0 177   0   1   0]\n",
      " [  0   0   0   0   3   0   0 162   1  13]\n",
      " [  0  19   0   0   0   2   4   0 135  14]\n",
      " [  0   4   0   0   0   1   0   0   3 172]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "##################################################\n",
    "#\t\t\t\t\t\t\t\t\t\t\t\t #\n",
    "# \t\t\tTuning the hyper-parameter for \t\t #\n",
    "#\t     linear discrimination after removal:  \t #\n",
    "#\t\t\t\tregularization penalty\t\t\t #\n",
    "#\t\t\t\t\t\t\t\t\t\t\t\t #\n",
    "##################################################\t \n",
    "\n",
    "# set regularization penalty\n",
    "regs = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "# an empty list to store validation accuracies\n",
    "val_scores_sgd = []\n",
    "\n",
    "# compute linear classifier accuracy for each regularization strength\n",
    "print('\\n'+50*'#')\n",
    "print('Hyper-parameters tunning for linear classifier after removal...')\n",
    "print(50*'#')\n",
    "best_sgd = None\n",
    "best_acc_sgd = -1\n",
    "for reg in regs:\n",
    "    sgd = linear_model.SGDClassifier(alpha=reg)\n",
    "    sgd.fit(Xtr, ytr)\n",
    "    val_acc_sgd = sgd.score(Xval, yval) # accuracy for validation set\n",
    "    val_scores_sgd.append(val_acc_sgd)\n",
    "    if val_acc_sgd > best_acc_sgd:\n",
    "    \tbest_sgd = sgd\n",
    "    \tbest_acc_sgd = val_acc_sgd\n",
    "\n",
    "# choose the best regularization penalty\n",
    "best_reg = regs[val_scores_sgd.index(max(val_scores_sgd))]\n",
    "print (\"Best alpha: {}\\n\".format(best_reg))\n",
    "\n",
    "\n",
    "# Validation accuracy\n",
    "y_pred_val_sgd = best_sgd.predict(Xval)\n",
    "print(\"Validation accuracy (Linear classifier) after removal: {:.4f}\".format(best_sgd.score(Xval, yval)))\n",
    "\n",
    "\n",
    "# compute linear classifier train time\n",
    "print('\\nComputing linear classifier training time after removal...')\n",
    "start = time.time()\n",
    "sgd = linear_model.SGDClassifier(alpha=best_reg)\n",
    "sgd.fit(X_train_new, y_train_new)\n",
    "print(\"alpha: {}, training took {:.4f} seconds.\\n\".format(best_reg, time.time() - start))\n",
    "\n",
    "# train set confusion matrix\n",
    "y_pred_train_sgd = sgd.predict(X_train_new)\n",
    "conf_sgd_train_re = confusion_matrix(y_train_new, y_pred_train_sgd)\n",
    "plot_confusion_matrix(conf_sgd_train_re, classes=tick_label,title=\"Confusion Matrix of linear classifier after removal (Train)\")\n",
    "\n",
    "\n",
    "# compute linear classifier test time\n",
    "start = time.time()\n",
    "print('\\nComputing linear classifier test time after removal...')\n",
    "y_pred_test_sgd = sgd.predict(X_test)\n",
    "print(\"alpha: {}, test took {:.4f} seconds.\\n\".format(best_reg, time.time() - start))\n",
    "print(\"Test accuracy after removal (linear classifier): {:.4f}\\n\".format(sgd.score(X_test, y_test)))\n",
    "\n",
    "# plot test set confusion matrix\n",
    "conf_sgd_test_re = confusion_matrix(y_test, y_pred_test_sgd)\n",
    "plot_confusion_matrix(conf_sgd_test_re, classes=tick_label,title=\"Confusion Matrix of linear classifier after removal (Test)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################\n",
      "Hyper-parameters tunning for MLP after removal...\n",
      "##################################################\n",
      "Best hidden_layer_sizes: 64, Best alpha: 1\n",
      "\n",
      "Validation accuracy after removal (MLP): 1.0000\n",
      "\n",
      "Computing MLP training time after removal ...\n",
      "hidden_layer_sizes: 64, alpha: 1, training took 4.4081 seconds.\n",
      "\n",
      "Confusion Matrix of MLP after removal (Train)\n",
      "[[374   0   0   0   0   0   0   0   0   0]\n",
      " [  0 364   0   0   0   0   0   0   0   0]\n",
      " [  0   0 369   0   0   0   0   0   0   0]\n",
      " [  0   0   0 371   0   0   0   0   0   0]\n",
      " [  0   0   0   0 369   0   0   0   0   0]\n",
      " [  0   0   0   0   0 364   0   0   0   0]\n",
      " [  0   0   0   0   0   0 373   0   0   0]\n",
      " [  0   0   0   0   0   0   0 382   0   0]\n",
      " [  0   0   0   0   0   0   0   0 351   0]\n",
      " [  0   0   0   0   0   0   0   0   0 351]]\n",
      "\n",
      "Computing MLP test time after removal ...\n",
      "hidden_layer_sizes: 64, alpha: 1, test took 0.0035 seconds.\n",
      "Test accuracy (MLP): 0.9527\n",
      "\n",
      "Confusion Matrix of MLP after removal (Test)\n",
      "[[177   0   0   0   1   0   0   0   0   0]\n",
      " [  0 171   1   0   0   1   0   0   3   6]\n",
      " [  0   1 174   1   0   0   0   1   0   0]\n",
      " [  1   0   2 171   0   3   0   1   2   3]\n",
      " [  0   0   0   0 178   0   0   0   3   0]\n",
      " [  0   0   0   0   0 180   0   0   0   2]\n",
      " [  1   1   0   0   0   0 178   0   1   0]\n",
      " [  0   0   0   0   2   8   0 165   2   2]\n",
      " [  0  10   0   0   0   4   1   0 155   4]\n",
      " [  1   2   0   1   4   2   0   0   7 163]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##################################################\n",
    "#\t\t\t\t\t\t\t\t\t\t\t\t #\n",
    "# \tTuning the hyper-parameter after removal:\t #\n",
    "#\t\t\t\tMultilayer perceptron\t\t\t #\n",
    "#\t\t\t\t\t\t\t\t\t\t\t\t #\n",
    "##################################################\t \n",
    "\n",
    "\n",
    "# compute mlp classifier accuracy for each set of parameters\n",
    "print('\\n'+50*'#')\n",
    "print('Hyper-parameters tunning for MLP after removal...')\n",
    "print(50*'#')\n",
    "best_mlp = None\n",
    "best_acc_mlp = -1\n",
    "best_hls = []\n",
    "best_reg = []\n",
    "hls = [64, 128, 256, (64,64), (128,128), (256,256)]\n",
    "regs = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "for hl in hls:\n",
    "    for reg in regs:\n",
    "    \tmlp = MLPClassifier(solver='adam', alpha=reg, hidden_layer_sizes=hl)\n",
    "    \tmlp.fit(Xtr, ytr)\n",
    "    \tval_acc_mlp = mlp.score(Xval, yval) # accuracy for validation set\n",
    "    \tval_scores_sgd.append(val_acc_sgd)\n",
    "    \tif val_acc_mlp > best_acc_mlp:\n",
    "    \t\tbest_mlp = mlp\n",
    "    \t\tbest_acc_mlp = val_acc_mlp\n",
    "    \t\tbest_hls = hl\n",
    "    \t\tbest_reg = reg\n",
    "\n",
    "# choose the best number of components\n",
    "#best_n_components = n_components_array[val_scores_lda.index(max(val_scores_lda))]\n",
    "\n",
    "# print best hyper-parameters\n",
    "print (\"Best hidden_layer_sizes: {}, Best alpha: {}\\n\".format(best_hls, best_reg))\n",
    "\n",
    "\n",
    "# Validation accuracy\n",
    "print(\"Validation accuracy after removal (MLP): {:.4f}\".format(best_mlp.score(Xval, yval)))\n",
    "\n",
    "\n",
    "# compute MLP train time\n",
    "print('\\nComputing MLP training time after removal ...')\n",
    "start = time.time()\n",
    "mlp = MLPClassifier(solver='adam', alpha=best_reg, hidden_layer_sizes=best_hls)\n",
    "mlp.fit(X_train_new, y_train_new)\n",
    "print(\"hidden_layer_sizes: {}, alpha: {}, training took {:.4f} seconds.\\n\".format(best_hls, best_reg,\\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t time.time() - start))\n",
    "\n",
    "\n",
    "# plot train set confusion matrix\n",
    "y_pred_train_mlp = mlp.predict(X_train_new)\n",
    "conf_mlp_train_re = confusion_matrix(y_train_new, y_pred_train_mlp)\n",
    "plot_confusion_matrix(conf_mlp_train_re, classes=tick_label,title=\"Confusion Matrix of MLP after removal (Train)\")\n",
    "\n",
    "\n",
    "# compute MLP test time\n",
    "start = time.time()\n",
    "print('\\nComputing MLP test time after removal ...')\n",
    "y_pred_test_mlp = mlp.predict(X_test)\n",
    "print(\"hidden_layer_sizes: {}, alpha: {}, test took {:.4f} seconds.\".format(best_hls, best_reg,\\\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t time.time() - start))\n",
    "# print test accuracy MLP\n",
    "print(\"Test accuracy (MLP): {:.4f}\\n\".format(mlp.score(X_test, y_test)))\n",
    "\n",
    "# plot test set confusion matrix\n",
    "conf_mlp_test_re = confusion_matrix(y_test, y_pred_test_mlp)\n",
    "plot_confusion_matrix(conf_mlp_test_re, classes=tick_label,title=\"Confusion Matrix of MLP after removal (Test)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########################################\n",
      "Accuracy per class (KNN)\n",
      "Class    Before Removal   After Removal\n",
      " 0       1.0000           1.0000\n",
      " 1       0.9835           0.9835\n",
      " 2       0.9831           0.9831\n",
      " 3       0.9727           0.9727\n",
      " 4       0.9779           0.9779\n",
      " 5       0.9890           0.9890\n",
      " 6       0.9945           0.9945\n",
      " 7       0.9665           0.9665\n",
      " 8       0.9253           0.9253\n",
      " 9       0.9556           0.9556\n",
      "\n",
      "########################################\n",
      "Accuracy per class (Decision Tree)\n",
      "Class    Before Removal   After Removal\n",
      " 0       0.9719           0.9551\n",
      " 1       0.8846           0.9286\n",
      " 2       0.8023           0.7740\n",
      " 3       0.8306           0.8033\n",
      " 4       0.7790           0.8508\n",
      " 5       0.8791           0.9121\n",
      " 6       0.9503           0.9558\n",
      " 7       0.7542           0.8045\n",
      " 8       0.8391           0.8391\n",
      " 9       0.8667           0.8111\n",
      "\n",
      "########################################\n",
      "Accuracy per class (Linear Classifier)\n",
      "Class    Before Removal   After Removal\n",
      " 0       0.9831           0.9944\n",
      " 1       0.8846           0.9176\n",
      " 2       0.9718           0.9379\n",
      " 3       0.9016           0.8689\n",
      " 4       0.9779           0.9448\n",
      " 5       0.9835           0.9341\n",
      " 6       0.9724           0.9779\n",
      " 7       0.9162           0.9050\n",
      " 8       0.8563           0.7759\n",
      " 9       0.9000           0.9556\n",
      "\n",
      "########################################\n",
      "Accuracy per class (MLP)\n",
      "Class    Before Removal   After Removal\n",
      " 0       0.9944           0.9944\n",
      " 1       0.9835           0.9396\n",
      " 2       0.9548           0.9831\n",
      " 3       0.9344           0.9344\n",
      " 4       0.9669           0.9834\n",
      " 5       0.9725           0.9890\n",
      " 6       0.9834           0.9834\n",
      " 7       0.9162           0.9218\n",
      " 8       0.9195           0.8908\n",
      " 9       0.9722           0.9056\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy per class before and after removal for test set KNN \n",
    "print('\\n'+40*'#')\n",
    "print('Accuracy per class (KNN)')\n",
    "acc_per_class(conf_knn_test, conf_knn_test_re)\n",
    "\n",
    "\n",
    "# compute accuracy per class before and after removal for test set  Decision Tree\n",
    "print('\\n'+40*'#')\n",
    "print('Accuracy per class (Decision Tree)')\n",
    "acc_per_class(conf_dtree_test, conf_dtree_test_re)\n",
    "\n",
    "# compute accuracy per class before and after removal for test set  Linear Classifier\n",
    "print('\\n'+40*'#')\n",
    "print('Accuracy per class (Linear Classifier)')\n",
    "acc_per_class(conf_sgd_test, conf_sgd_test_re)\n",
    "\n",
    "# compute accuracy per class before and after removal for test set  MLP\n",
    "print('\\n'+40*'#')\n",
    "print('Accuracy per class (MLP)')\n",
    "acc_per_class(conf_mlp_test, conf_mlp_test_re)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
